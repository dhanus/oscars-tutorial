{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good data science projects start with a clear understanding of the data and where it comes from. In this tutorial, we will use HTTP requests and BeautifulSoup to write a web scraper, and then we will use NumPy, Pandas, matplotlib, sklearn, and Jupyter notebooks to explore that data carefully, and eventually develop an effective model.\n",
    "\n",
    "The goal of this part of the tutorial is build your skills in: \n",
    "\n",
    "- asking good questions\n",
    "- finding good data\n",
    "- scraping a web page\n",
    "- cleaning and manipulating data\n",
    "- using pandas\n",
    "- exploratory data visualization\n",
    "- thinking about data and what features might be used to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We're going to make a movie! \n",
    "\n",
    "Our first goal today is to learn about what makes a box office hit. So to start off let's pretend that we are some (very data savvy) movie producers, and we want to make a movie that will make us a metric ton of money. So what are some features of movies that might correlate with making a ton of money? Is it the budget? The actors? \n",
    "\n",
    "##### Example 1.  Black Panther may be a contender for best movie EVARR\n",
    "\n",
    "<img src=\"http://www.nerdcoremovement.com/wp-content/uploads/Black-Panther-1-938x535.jpg\"\n",
    "     alt=\"Example Great Movie\"\n",
    "     style=\"float: left; margin-right: 10px;\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out! \n",
    "\n",
    "List some of the features that you think you might want to consider as you make you make **The Best Movie Ever**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asking good questions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"A good question is one that you can answer!\"*\n",
    "\n",
    "Think about   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@help can someone come up with some exercises for this? Maybe have them rewrite some causal statements as correlational?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting good data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some good places to get data? \n",
    "\n",
    "There are a lot of good places to get data! If you want to start looking at some data sets, here are a few repositories. \n",
    "   - [Kaggle](https://www.kaggle.com/datasets)  \n",
    "   - [FiveThirtyEight](https://data.fivethirtyeight.com/)\n",
    "   - [Government Data](https://catalog.data.gov/dataset)\n",
    "   - APIs (e.g. [IMDBPy](https://imdbpy.sourceforge.io/))\n",
    "   - Scraping the Internet! \n",
    "    \n",
    "### What sites should you scrape? \n",
    "\n",
    "When you want to find a certain type of data, try to find data that is structured (e.g. Wikipedia). Tables, headings, and text boxes stand out, and can be easier to find. **Also, remember to read the Terms of Service for the site that you plan to scrape.**\n",
    "\n",
    "### Try it out! \n",
    "\n",
    "We are going to use data to make **The Best Movie Ever**, but what are some good places for us to get that data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start scraping \n",
    "\n",
    "To get started, we need to import several packages. We explain what several of these imports are below in the comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The %... is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline \n",
    "# See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "from matplotlib import rcParams # special matplotlib argument for improved plots\n",
    "from collections import defaultdict \n",
    "#from imdb import IMDb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import cPickle as pickle\n",
    "# import seaborn as sns\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# sns.set_context(\"poster\")\n",
    "\n",
    "import io \n",
    "import time\n",
    "import requests\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [Seaborn](http://seaborn.pydata.org/) to give us a nicer default color palette, with our plots being of large (poster) size and with a white-grid background. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Box Office Mojo \n",
    "\n",
    "To get the text from the website to your local machine, we will use a GET request, which is available in the [Requests](http://docs.python-requests.org/en/master/) library. \n",
    "\n",
    "To get started exploring the text that you bring to your local macine, we will use [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/). If you are familiar with another scraping library like [PyQuery](https://pythonhosted.org/pyquery/) or [Scrapy](https://scrapy.org/), feel free to do this exercise using those instead (or in addition! :)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# The \"requests\" library makes working with HTTP requests easier\n",
    "# than the built-in urllib libraries.\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we access a webpage and download the HTML using requests. When we make a GET response, we get an HTTP response object back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_2018 = requests.get(\"http://www.boxofficemojo.com/yearly/chart/?view=releasedate&view2=domestic&page=1&yr=2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a HTTP response 200, which means that the request went through without issue. If you get another HTTP response, you can look it up in [this list](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) to determine what it is. \n",
    "\n",
    "Alternatively, if you like your HTTP status codes illustrated as cat gifs, you can look up your codes using [http.cat](https://http.cat/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print r_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of awesome things going in this response object. Most relevantly, it has returned all the text from the page that we made the request from to us, so we can look at it on our local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## uncomment the line below to see the html returned by the response \n",
    "#print r_2018.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this blob of text is not difficult for our computer to search through, it can be a little difficult for us to wrap human brains around. Another way that we can look at the text are: \n",
    "(a) Right click > View Source. \n",
    "\n",
    "@help insert screen shot \n",
    "\n",
    "(b) Right click > Inspect Item \n",
    "\n",
    "@help insert screen shot \n",
    "\n",
    "(c) View > Developer > Developer Tools \n",
    "\n",
    "@help insert screen shot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the HTML \n",
    "\n",
    "Which parts of this text do we need to get information about these movies? How can we pull out only the information that we want? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*double-click to type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Preview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example correlation plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
