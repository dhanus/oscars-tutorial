{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good data science projects start with a clear understanding of the data and where it comes from. In this tutorial, we will use HTTP requests and BeautifulSoup to write a web scraper, and then we will use NumPy, Pandas, matplotlib, sklearn, and Jupyter notebooks to explore that data carefully.\n",
    "\n",
    "The goal of this part of the tutorial is build your skills in: \n",
    "\n",
    "- asking good questions\n",
    "- finding good data\n",
    "- scraping a web page\n",
    "- cleaning and manipulating data\n",
    "- using pandas\n",
    "- exploratory data visualization\n",
    "- thinking about data and what features might be used to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We're going to make a movie! \n",
    "\n",
    "Our first goal today is to learn about what makes a box office hit. So to start off let's pretend that we are some (very data savvy) movie producers, and we want to make a movie that will make us a metric ton of money. So what are some features of movies that might correlate with making a ton of money? Is it the budget? The actors? \n",
    "\n",
    "##### Example 1.  Black Panther may be a contender for best movie EVARR\n",
    "\n",
    "<img src=\"http://www.nerdcoremovement.com/wp-content/uploads/Black-Panther-1-938x535.jpg\"\n",
    "     alt=\"Example Great Movie\"\n",
    "     style=\"float: left; margin-right: 10px;\"/>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out!  \n",
    "\n",
    "List some of the features that you think you might want to consider as you make you make **The Best Movie Ever**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asking good questions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"A good question is one that you can answer!\"**\n",
    "\n",
    "Many of the questions that we want to ask are causal (e.g. \"Will this script be a box office hit?\"), but causality can be difficult to prove. You can read more about some ways to argue for causality. \n",
    "\n",
    "In the exploratory data analysis phase, most of the questions you will be able to answer will be of a different "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@help can someone come up with some exercises for this? Maybe have them rewrite some causal statements as correlational?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting good data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are some good places to get data? \n",
    "\n",
    "There are a lot of good places to get data! If you want to start looking at some data sets, here are a few repositories. \n",
    "   - [Kaggle](https://www.kaggle.com/datasets)  \n",
    "   - [FiveThirtyEight](https://data.fivethirtyeight.com/)\n",
    "   - [Government Data](https://catalog.data.gov/dataset)\n",
    "   - APIs (e.g. [IMDBPy](https://imdbpy.sourceforge.io/))\n",
    "   - Scraping the Internet! \n",
    "    \n",
    "### What sites should you scrape? \n",
    "\n",
    "When you want to find a certain type of data, try to find data that is structured (e.g. Wikipedia). Tables, headings, and text boxes stand out, and can be easier to find. **Also, remember to read the Terms of Service for the site that you plan to scrape.**\n",
    "\n",
    "### Try it out! \n",
    "\n",
    "We are going to use data to make **The Best Movie Ever**, but what are some good places for us to get that data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start scraping \n",
    "\n",
    "To get started, we need to import several packages. We explain what several of these imports are below in the comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named seaborn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-509f24a303ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# sns.set_style(\"whitegrid\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# sns.set_context(\"poster\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named seaborn"
     ]
    }
   ],
   "source": [
    "# The %... is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline \n",
    "# See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "from matplotlib import rcParams # special matplotlib argument for improved plots\n",
    "from collections import defaultdict \n",
    "#from imdb import IMDb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import cPickle as pickle\n",
    "import seaborn as sns\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# sns.set_context(\"poster\")\n",
    "\n",
    "import io \n",
    "import time\n",
    "import requests\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [Seaborn](http://seaborn.pydata.org/) to give us a nicer default color palette, with our plots being of large (poster) size and with a white-grid background. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Box Office Mojo \n",
    "\n",
    "To get the text from the website to your local machine, we will use a GET request, which is available in the [Requests](http://docs.python-requests.org/en/master/) library. \n",
    "\n",
    "To get started exploring the text that you bring to your local macine, we will use [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/). If you are familiar with another scraping library like [PyQuery](https://pythonhosted.org/pyquery/) or [Scrapy](https://scrapy.org/), feel free to do this exercise using those instead (or in addition! :)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# The \"requests\" library makes working with HTTP requests easier\n",
    "# than the built-in urllib libraries.\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we access a webpage and download the HTML using requests. When we make a GET response, we get an HTTP response object back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_2018 = requests.get(\"http://www.boxofficemojo.com/yearly/chart/?view=releasedate&view2=domestic&page=1&yr=2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a HTTP response 200, which means that the request went through without issue. If you get another HTTP response, you can look it up in [this list](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) to determine what it is. \n",
    "\n",
    "Alternatively, if you like your HTTP status codes illustrated as cat gifs, you can look up your codes using [http.cat](https://http.cat/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print r_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of awesome things going in this response object. Most relevantly, it has returned all the text from the page that we made the request from to us, so we can look at it on our local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## uncomment the line below to see the html returned by the response \n",
    "#print r_2018.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this blob of text is not difficult for our computer to search through, it can be a little difficult for us to wrap human brains around. Another way that we can look at the text are: \n",
    "(a) Right click > View Source. \n",
    "\n",
    "@help insert screen shot \n",
    "\n",
    "(b) Right click > Inspect Item \n",
    "\n",
    "@help insert screen shot \n",
    "\n",
    "(c) View > Developer > Developer Tools \n",
    "\n",
    "@help insert screen shot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out! \n",
    "\n",
    "### Understanding the HTML \n",
    "\n",
    "Which parts of this text do we need to get information about these movies? How can we pull out only the information that we want? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*double-click to type your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out!\n",
    "\n",
    "### Requests \n",
    "\n",
    "Scrape Box Office Mojo's data for movies from 2016 to 2018 and store the page text in a dictionary. Remember to use the time(s) function to add a wait before each GET request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "years = xrange(2016,2018)\n",
    "pages = xrange(1,9)\n",
    "year_pagetxt = {}\n",
    "for year in years: \n",
    "    pagestext = {}\n",
    "    for page in pages: \n",
    "        r = requests.get(\"http://www.boxofficemojo.com/yearly/chart/?page=%s&view=releasedate&view2=domestic&yr=%s&p=.htm\"%(page, year))\n",
    "        pagestext[page] = r.text\n",
    "        time.sleep(1)\n",
    "    year_pagetxt[year] = pagestext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it out! \n",
    "\n",
    "### Beautiful Soup \n",
    "\n",
    "Store the information from the table in the dictionary with the column heading as the key and a list of values as the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here \n",
    "\n",
    "# This loop cycles through the data obtained on Box Office Mojo\n",
    "## And placed in a dictionary for recall later when folding in IMDb information\n",
    "movie_budget = defaultdict(list) \n",
    "for year in years: \n",
    "    for page in pages: \n",
    "        soup = BeautifulSoup(year_pagetxt[year][page], \"html.parser\")\n",
    "        rows = soup.find_all(\"font\", attrs={'size':'2'})\n",
    "           \n",
    "        start = 10 \n",
    "        for i in range(start,len(rows)-2):\n",
    "            t = rows[i].get_text()\n",
    "            if unicode('Summary of') in t: \n",
    "                break\n",
    "            elif (i-start) % 9 == 0: \n",
    "                movie_budget['rank'].append(t)\n",
    "            elif (i-start) % 9 == 1: \n",
    "                movie_budget['year'].append(year)\n",
    "                r = '('+str(year)\n",
    "                if unicode(r) in t: \n",
    "                    j = t.index(unicode(r))\n",
    "                    movie_budget['title'].append(t[:j])\n",
    "                else: \n",
    "                    movie_budget['title'].append(t)\n",
    "            elif (i-start) % 9 == 2: \n",
    "                movie_budget['studio'].append(t)\n",
    "            elif (i-start) % 9 == 3: \n",
    "                movie_budget['gross'].append(t)\n",
    "            elif (i-start) % 9 == 4: \n",
    "                movie_budget['gross theaters'].append(t)\n",
    "            elif (i-start) % 9 == 5: \n",
    "                movie_budget['opening'].append(t)\n",
    "            elif (i-start) % 9 == 6: \n",
    "                movie_budget['opening theaters'].append(t)\n",
    "            elif (i-start) % 9 == 7: \n",
    "                movie_budget['open'].append(t)\n",
    "            elif (i-start) % 9 == 8: \n",
    "                movie_budget['close'].append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Preview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any fancy statistical modeling, we need to understand our data. To do this, there is no substitute for looking at our data, making some scatter plots, and getting a better idea of what it looks like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the data \n",
    "\n",
    "@help explain the data and what is limiteddf \n",
    "\n",
    "\n",
    "### Some Features to Explore \n",
    "\n",
    "- **Movie Budget**\n",
    "- **Opening Weekend**\n",
    "- **Opening Theaters**\n",
    "- **IMDb rating**\n",
    "- **Seasonality**\n",
    "- **MPAA Rating**\n",
    "- **Power Studios**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example correlation plots \n",
    "\n",
    "Remember, the goal of all of this data analysis is to make a ton of money, so it might make sense to see how each of these factors correlate with **gross revenue**. \n",
    "\n",
    "### Linear regression \n",
    "\n",
    "One nice way of exploring how two variables look in relationship to one another is to make a regression plot. A nice explanation of linear regression can be found [here](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html). Most data analysis tools have some way of doing linear regression. In this tutorial, we will use the [seaborn regplot](https://seaborn.pydata.org/tutorial/regression.html) to plot regressions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross Revenue vs. Opening Weekend Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2a8a0efc8cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gross\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"opening_gross\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimiteddf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.regplot(y=\"gross\", x=\"opening_gross\", data=limiteddf, fit_reg = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross Revenue vs. Opening Weekend Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.regplot(y=\"gross\", x=\"opening_theaters\", data=limiteddf, fit_reg = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross Revenue vs Allocated Budget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.regplot(y=\"gross\", x=\"budget\", data=limiteddf, fit_reg = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross revenue vs IMDB rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-51bf6d8ea5c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gross\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rating\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimiteddf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.regplot(y=\"gross\", x=\"rating\", data=limiteddf, fit_reg = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: What other features? \n",
    "\n",
    "There is always more to explore and discover in the data. Is there anything else that you wish that we had explored together? If so, feel free to try it out now! \n",
    "\n",
    "If you find yourself feeling stuck, you can check out [oscarpredictor.github.io](http://oscarpredictor.github.io/) for inspiration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
